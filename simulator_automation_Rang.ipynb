{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default needs\n",
    "import dill\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Importing Environments\n",
    "from environments import square_room\n",
    "\n",
    "from utils.agent_utils import calc_win_percentage\n",
    "\n",
    "# Combat Handler\n",
    "from combat_handler import CombatHandler\n",
    "\n",
    "# agents\n",
    "from agents import TIME_LIMIT\n",
    "\n",
    "# Actions and Players\n",
    "from actions import *\n",
    "from players import dungeon_master\n",
    "from players import hayden\n",
    "from utils.dnd_utils import roll_dice\n",
    "from creatures import Creature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import time\n",
    "start_time = str(datetime.now().isoformat()[:-7]).replace(':',\"-\")\n",
    "\n",
    "EXPT_NAME = \"Ranger_PPO_Dense\"\n",
    "MODEL_FILE = \"results\\AnandakrishnanDumps\\PPO_Dense\\model_PPO_Rang_ITERS_10000.pickle\"\n",
    "\n",
    "# log_file_name = \"logs\\sims\\Simulations_\"+EXPT_NAME+\"_\"+start_time+\".log\"\n",
    "\n",
    "# logging.basicConfig(filename=log_file_name, filemode='w', level=logging.INFO)\n",
    "# logger = logging.getLogger(\"RUNNER\")\n",
    "\n",
    "# print(\"GONNA LOG AT \",log_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO n Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def report_win_percentages(winner_list, num_games, combatants, total_rewards, last_states, num_actions_takens, details = True):\n",
    "    \"\"\"\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    win_percentages = calc_win_percentage(winner_list[-num_games:], combatants)\n",
    "    last_states = torch.cat(last_states).data.numpy()\n",
    "    print(\"Win percentages: {}\\t\".format(win_percentages))\n",
    "    logger.info((\"Win percentages: {}\\t\".format(win_percentages)))\n",
    "\n",
    "    results = list(zip(winner_list[-num_games:], total_rewards[-num_games:], last_states, num_actions_takens))\n",
    "    results = sorted(results, key=lambda x: -x[1])\n",
    "    if details:\n",
    "        for winner, avg_reward, last_state, num_actions_taken in results:\n",
    "            print(\" {}: {} ({}) \\t\\t{}\".format(winner, avg_reward, last_state, num_actions_taken))\n",
    "    print(\"----------------------\\n\")\n",
    "\n",
    "\n",
    "def intialize_combatants(combatants, combat_handler):\n",
    "    \"\"\"\n",
    "    :param combatants:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    [combatant.initialize(combat_handler) for combatant in combatants]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.agent_utils import EGreedyPolicy\n",
    "from utils.agent_utils import Experience\n",
    "from utils.agent_utils import filter_illegal_actions\n",
    "from utils.agent_utils import filter_out_final_states\n",
    "from utils.agent_utils import mean_sq_error\n",
    "from utils.agent_utils import PrioritizedMemory\n",
    "from utils.agent_utils import SARSAExperience\n",
    "from utils.agent_utils import DuelingNet\n",
    "from utils.agent_utils import ActorCritic\n",
    "from agents import RandomStrategy\n",
    "from agents import Strategy\n",
    "\n",
    "class FunctionApproximation_no_train(Strategy):\n",
    "    def __init__(self, max_training_steps=5e6, epsilon_start=0.3, epsilon_end=0.05, alpha=1e-4,\n",
    "                 gamma=0.999, update_frequency=5e4, memory_length=1024, batch_size=128, policy_net = None):\n",
    "        self.max_training_steps = max_training_steps\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.update_frequency = update_frequency\n",
    "        self.training_iteration = 0\n",
    "        self.t = 0\n",
    "        self.policy = EGreedyPolicy(n_steps=max_training_steps, epsilon_start=epsilon_start, epsilon_end=epsilon_end)\n",
    "        self.w = None\n",
    "        self.w_stored = None\n",
    "        self.action_to_index = None\n",
    "        self.index_to_action = None\n",
    "        self.n_states = None\n",
    "        self.n_actions = None\n",
    "\n",
    "        self.policy_net = policy_net\n",
    "        self.target_net = None\n",
    "        self.optimizer = None\n",
    "        self.memory = PrioritizedMemory(memory_length)\n",
    "        self.name = \"DQN\"\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.learning_rate_decay_freq = TIME_LIMIT * 100\n",
    "        self.n_learning_rate_decays = 0\n",
    "        self.n_weight_updates = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def determine_enemy(creature, combat_handler):\n",
    "        \"\"\"\n",
    "        :param creature:\n",
    "        :param combat_handler:\n",
    "        :return enemy:\n",
    "        \"\"\"\n",
    "        enemy = None\n",
    "        combatants = combat_handler.combatants\n",
    "        for combatant in combatants:\n",
    "            if combatant != creature:\n",
    "                enemy = combatant\n",
    "        return enemy\n",
    "\n",
    "    def initialize(self, creature, combat_handler):\n",
    "        # Initialize weights if needed\n",
    "        if self.policy_net is None:\n",
    "            print(\"NO NET\")\n",
    "            state = self.get_current_state(creature=creature, combat_handler=combat_handler)\n",
    "            self.initialize_weights(creature, state)\n",
    "        else:\n",
    "            # print(self.policy_net)\n",
    "            \n",
    "            # print(state.size(),state)\n",
    "            try:\n",
    "#                 print(\"GETTING STATE\")\n",
    "                state = self.get_current_state(creature=creature, combat_handler=combat_handler)\n",
    "#                 print(state)\n",
    "                # print(state.size(),state)\n",
    "            except:\n",
    "                # print(\"PROBLEM\")\n",
    "                pass\n",
    "            if state is None:\n",
    "                state = torch.zeros([1,9])\n",
    "            # print(state)\n",
    "            self.activate_weights(creature, state)\n",
    "        # print(self.n_actions)\n",
    "\n",
    "        # Obtain dictionaries translating index to actions and vice versa\n",
    "        action_indicies = zip(creature.actions, range(self.n_actions))\n",
    "        self.action_to_index = {action: index for action, index in action_indicies}\n",
    "        self.index_to_action = {index: action for action, index in self.action_to_index.items()}\n",
    "\n",
    "class PPO_No_Train(FunctionApproximation_no_train):\n",
    "    def __init__(self, max_training_steps=1e5, epsilon_start=0.5, epsilon_end=0.05, alpha=1e-5,\n",
    "                 gamma=0.99, update_frequency=30000, memory_length=16834, batch_size=128, \n",
    "                 win_reward=5,lose_reward=0,attack_dealt_reward=0,attack_recieved_reward=0, policy_net=None):\n",
    "        super().__init__(\n",
    "            max_training_steps, epsilon_start, epsilon_end, alpha, gamma, update_frequency, memory_length, batch_size, policy_net\n",
    "        )\n",
    "        self.name = \"PPO\"\n",
    "        self.optimizer = None\n",
    "        self.win_reward             = win_reward\n",
    "        self.lose_reward            = lose_reward\n",
    "        self.attack_dealt_reward    = attack_dealt_reward\n",
    "        self.attack_recieved_reward = attack_recieved_reward\n",
    "\n",
    "    def activate_weights(self, creature, state=torch.zeros([1,9])):\n",
    "#         print(creature, state)\n",
    "        self.n_states = state.shape[1]\n",
    "        self.n_actions = len(creature.actions)\n",
    "        h = self.n_actions\n",
    "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=self.alpha)\n",
    "\n",
    "\n",
    "    def update_step(self, action, creature, current_state, next_state, combat_handler):\n",
    "        pass\n",
    "\n",
    "    def sample_action(self, creature, combat_handler, increment_counter=True, state=None):\n",
    "        \"\"\"\n",
    "        Returns an action or an action_index\n",
    "\n",
    "        :param creature:\n",
    "        :param combat_handler:\n",
    "        :param increment_counter:\n",
    "        :param state:\n",
    "        :return: action_index\n",
    "        \"\"\"\n",
    "        # Obtain state / actions:\n",
    "        if state is None:\n",
    "            state = self.get_current_state(creature=creature, combat_handler=combat_handler)\n",
    "\n",
    "        dist, value = self.policy_net(state)\n",
    "        action_index = dist.sample()\n",
    "        log_prob = dist.log_prob(action_index)\n",
    "        action = self.index_to_action[action_index.data.numpy()[0]]\n",
    "\n",
    "        # Return action\n",
    "        return action, log_prob, value\n",
    "\n",
    "    def evaluate_state_and_action(self, creature, combat_handler, state, action):\n",
    "        \"\"\"\n",
    "        Obtain:\n",
    "           - the probability of selection `action_index` when in input state 'state'\n",
    "           - the value of the being in input state `state`\n",
    "        :param creature:\n",
    "        :param combat_handler:\n",
    "        :param action:\n",
    "        :param state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Obtain state and action index:\n",
    "        action_index = self.action_to_index.get(action)\n",
    "\n",
    "        # Check if creature hadn't taken any actions.\n",
    "        if action_index is None:\n",
    "            return\n",
    "\n",
    "        # Convert to tensor\n",
    "        action_index = torch.tensor(action_index)\n",
    "\n",
    "        # Check if end of combat state\n",
    "        if state is None:\n",
    "            state = self.get_current_state(creature=creature, combat_handler=combat_handler)\n",
    "\n",
    "        dist, value = self.policy_net(state)\n",
    "        log_prob = dist.log_prob(action_index)\n",
    "        return log_prob, value\n",
    "\n",
    "    def get_gae(self, trajectory, lmbda=0.95):\n",
    "        \"\"\"\n",
    "        :param trajectory:\n",
    "        :param lmbda:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # Todo: replace this codeblock\n",
    "        rewards = [t[2] for t in trajectory]\n",
    "        values = [t[-1] for t in trajectory]\n",
    "        dummy_next_value = 0  # should get masked out\n",
    "        values = values + [dummy_next_value]\n",
    "        masks = [t[3] is not None for t in trajectory]\n",
    "\n",
    "        gae = 0\n",
    "        returns = []\n",
    "\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            delta = rewards[step] + self.gamma * values[step + 1] * masks[step] - values[step]\n",
    "            gae = delta + self.gamma * lmbda * masks[step] * gae\n",
    "            returns.insert(0, gae + values[step])\n",
    "\n",
    "        returns = torch.cat(returns)\n",
    "        return returns\n",
    "\n",
    "    def get_returns(self, trajectory):\n",
    "        rewards = [t[2] for t in trajectory]\n",
    "        is_terminals = [t[3] is None for t in trajectory]\n",
    "        discounted_rewards = list()\n",
    "\n",
    "        for reward, is_terminal in reversed(list(zip(rewards, is_terminals))):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + self.gamma * discounted_reward\n",
    "            discounted_rewards.insert(0, [discounted_reward])\n",
    "\n",
    "        discounted_rewards = torch.tensor(discounted_rewards)\n",
    "\n",
    "        return discounted_rewards\n",
    "\n",
    "    @staticmethod\n",
    "    def select_random_batch(current_states, actions, log_probs,returns, advantages, mini_batch_size):\n",
    "        random_indicies = np.random.randint(0, len(current_states), mini_batch_size)\n",
    "\n",
    "        batch_current_states = current_states[random_indicies]\n",
    "        batch_actions = actions[random_indicies]\n",
    "        batch_log_probs = log_probs[random_indicies]\n",
    "        batch_returns = returns[random_indicies]\n",
    "        batch_advantages = advantages[random_indicies]\n",
    "\n",
    "        return batch_current_states, batch_actions, batch_log_probs, batch_returns, batch_advantages\n",
    "\n",
    "    def update_step_trajectory(self, trajectory, clip_val=0.2):\n",
    "        pass\n",
    "\n",
    "    def determine_reward(self, creature, current_state, next_state, combat_handler):\n",
    "        \"\"\"\n",
    "        :param creature:\n",
    "        :param current_state:\n",
    "        :param next_state:\n",
    "        :param combat_handler:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "\n",
    "        enemy = self.determine_enemy(creature, combat_handler)\n",
    "\n",
    "\n",
    "        # Winner\n",
    "        if next_state is None:\n",
    "            if not enemy.is_alive():\n",
    "                reward += self.win_reward\n",
    "            else:\n",
    "                reward += self.lose_reward \n",
    "\n",
    "        # Get raw state\n",
    "        raw_next_state = self.get_raw_state(creature, enemy, combat_handler)\n",
    "\n",
    "        # Damage done\n",
    "        damage_done = (current_state - raw_next_state)[0][1]\n",
    "        # print(\"DMG DONE : \",damage_done)\n",
    "        if float(damage_done) > 0:\n",
    "            reward += self.attack_dealt_reward\n",
    "\n",
    "        # Damage taken\n",
    "        damage_taken = (raw_next_state - current_state)[0][0]\n",
    "        # print(\"DMG TAKEN : \",damage_taken)\n",
    "        if float(damage_taken) < 0:\n",
    "            reward += self.attack_recieved_reward\n",
    "\n",
    "        # print(reward)\n",
    "        # input(\"CONTINUE ?\")\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUtomator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAMES DONE :  10\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  20\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  30\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  40\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  50\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  60\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  70\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  80\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  90\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  100\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  110\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  120\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  130\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  140\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  150\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  160\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  170\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  180\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  190\n",
      "Win percentages: [('Leotris', 0.8), ('Strahd', 0.2)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  200\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  210\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  220\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  230\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  240\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  250\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  260\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  270\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  280\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  290\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  300\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  310\n",
      "Win percentages: [('Leotris', 0.7), ('Strahd', 0.3)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  320\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  330\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  340\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  350\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  360\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  370\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  380\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  390\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  400\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  410\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  420\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  430\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  440\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  450\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  460\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  470\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  480\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  490\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  500\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  510\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  520\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  530\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  540\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  550\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  560\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  570\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  580\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  590\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  600\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  610\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  620\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  630\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  640\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  650\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  660\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  670\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  680\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  690\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  700\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  710\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  720\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  730\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  740\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  750\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  760\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  770\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  780\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  790\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  800\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  810\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  820\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  830\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  840\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  850\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  860\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  870\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  880\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  890\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  900\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  910\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  920\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  930\n",
      "Win percentages: [('Leotris', 0.9), ('Strahd', 0.1)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  940\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  950\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  960\n",
      "Win percentages: [('Leotris', 0.8), ('Strahd', 0.2)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  970\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  980\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  990\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n",
      "GAMES DONE :  1000\n",
      "Win percentages: [('Leotris', 1.0), ('Strahd', 0)]\t\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 1000\n",
    "\n",
    "policy_net_trained = dill.load(open(MODEL_FILE, \"rb\"))\n",
    "\n",
    "winner_list = []\n",
    "total_rewards = []\n",
    "last_states = []\n",
    "num_actions_takens = []\n",
    "ranger = Creature(\n",
    "    player=hayden,\n",
    "    name=\"Leotris\",\n",
    "    hit_points=28,\n",
    "    armor_class=14,\n",
    "    resistance = 0,\n",
    "    actions=[MoveLeft(), MoveRight(), MoveUp(), MoveDown(), DoNotMove(), shortsword_slash, handcrossbow_shot],\n",
    "    location=np.array([5, 10]),\n",
    "    symbol=\"x\",\n",
    "        strategy=PPO_No_Train(win_reward=50,lose_reward=-50,\n",
    "                              attack_dealt_reward=1,attack_recieved_reward=-1,\n",
    "                              policy_net=policy_net_trained)\n",
    "    )\n",
    "\n",
    "manticore = Creature(\n",
    "        player=dungeon_master,\n",
    "        name=\"Strahd\",\n",
    "        hit_points=95,\n",
    "        armor_class=16,\n",
    "        actions=[MoveLeft(), MoveRight(), MoveUp(), MoveDown(), DoNotMove(), bite, tail_spike],\n",
    "        level_1_spell_slots = 10,\n",
    "        location=np.array([5, 5]),\n",
    "        symbol=\"@\",\n",
    "        strategy=RandomStrategy()\n",
    "    )\n",
    "\n",
    "for i in range(n_iters):\n",
    "#     ranger = Creature(\n",
    "#             player=hayden,\n",
    "#             name=\"Leotris\",\n",
    "#             hit_points=16,\n",
    "#             armor_class=11,\n",
    "#             resistance = 0,\n",
    "#             actions=[MoveLeft(), MoveRight(), MoveUp(), MoveDown(), DoNotMove(), fire_bolt_cantrip, ray_of_frost_cantrip, chromatic_orb_level_1, magic_missile_level_1, scorching_ray_level_2, aganazzars_scorcher_level_2],\n",
    "#             location=np.array([5, 10]),\n",
    "#             level_1_spell_slots = 3,\n",
    "#             level_2_spell_slots = 1,\n",
    "#             symbol=\"x\",\n",
    "#             strategy=PPO_No_Train(win_reward=50,lose_reward=-50,\n",
    "#                                   attack_dealt_reward=1,attack_recieved_reward=-1,\n",
    "#                                   policy_net=policy_net_trained)\n",
    "#         )\n",
    "\n",
    "#     manticore = Creature(\n",
    "#             player=dungeon_master,\n",
    "#             name=\"Strahd\",\n",
    "#             hit_points=95,\n",
    "#             armor_class=16,\n",
    "#             actions=[MoveLeft(), MoveRight(), MoveUp(), MoveDown(), DoNotMove(), bite, tail_spike],\n",
    "#             level_1_spell_slots = 10,\n",
    "#             location=np.array([5, 5]),\n",
    "#             symbol=\"@\",\n",
    "#             strategy=RandomStrategy()\n",
    "#         )\n",
    "    combat_handler = CombatHandler(\n",
    "        environment=square_room,\n",
    "        combatants=[ranger, manticore],\n",
    "        time_limit=TIME_LIMIT\n",
    "    )\n",
    "    intialize_combatants([ranger, manticore], combat_handler=combat_handler)\n",
    "    winner, total_reward, last_state, num_actions_taken = combat_handler.run_no_train()\n",
    "\n",
    "    winner_list.append(winner)\n",
    "    total_rewards.append(total_reward)\n",
    "    last_states.append(last_state)\n",
    "    num_actions_takens.append(num_actions_taken)\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(\"GAMES DONE : \",i+1)\n",
    "        report_win_percentages(\n",
    "                    winner_list=winner_list,\n",
    "                    num_games=10,\n",
    "                    combatants=[ranger, manticore],\n",
    "                    total_rewards=total_rewards,\n",
    "                    last_states=last_states,\n",
    "                    num_actions_takens=num_actions_takens,\n",
    "                    details = False\n",
    "        )\n",
    "\n",
    "    # dill.dump(winner_list, open(\"results/sims/Simulation_winner_list_{}_EXPT_{}_STARTED_{}_NITERS{}.pickle\".format(ranger.strategy.name, EXPT_NAME, start_time, n_iters), \"wb\"))\n",
    "    # dill.dump(total_rewards, open('results/sims/Simulation_reward_list_{}_EXPT_{}_STARTED_{}_NITERS{}.pickle'.format(ranger.strategy.name, EXPT_NAME, start_time, n_iters), \"wb\"))\n",
    "    # dill.dump(num_actions_takens, open('results/sims/Simulation_num_actions_taken_{}_EXPT_{}_STARTED_{}_NITERS{}.pickle'.format(ranger.strategy.name, EXPT_NAME, start_time, n_iters), \"wb\"))\n",
    "    # dill.dump(last_states, open('results/sims/Simulation_last_states_{}_EXPT_{}_STARTED_{}_NITERS{}.pickle'.format(ranger.strategy.name, EXPT_NAME, start_time, n_iters), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_Arr = []\n",
    "for i in range(len(winner_list)):\n",
    "    Result_Arr.append([winner_list[i],total_rewards[i],num_actions_takens[i],last_states[i]])\n",
    "df = pd.DataFrame(Result_Arr, columns=['winner','reward','num_actions','last_states'])\n",
    "df.to_csv('results/sims/csvs/Simulation_{}_EXPT_{}_STARTED_{}_NSIMS{}.csv'.format(ranger.strategy.name, EXPT_NAME, start_time, n_iters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Leotris', 'Strahd'], dtype='<U7'), array([972,  28], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(np.array(winner_list),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('cs5446_dnd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4b9ad229121b29662cfeadce241473fe91dfdaf5146c5435feacc558a449858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
